---
title: "newton_method"
author: "Jungang Zou"
date: "3/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(glmnet)
library(matlib)

```

# Loading the Loglike, gradient, hess
```{r}
try(source("./loglike_grad_hess_func.R"), silent = TRUE)
```



# Newton Method
```{r}
newton_optimize = function(x, y, beta = NULL, tol = 1e-10, lambda_init = 1, decay_rate = 0.5){
  if (is.null(beta))
    beta = matrix(rep(0, ncol(x)))
  optimization = func(x, y, beta)
  step = 1
  previous_loglik = -optimization$loglik

  while (previous_loglik > tol) {
    print(paste("step:", step, "  positive loglike loss:", -optimization$loglik))
    lambda = lambda_init
    beta_new = beta - lambda * inv(optimization$Hess) %*% optimization$grad
    # the error occurs here, that the positive loglike loss is Inf at the 12th step.
    optimization = func(x, y, beta_new)
    print(-optimization$loglik)

    # since the loglike loss is Inf which is larger than loglike loss at previous step, the having process starts
    while (previous_loglik <= -optimization$loglik) {
      lambda = lambda * decay_rate
      beta_new = beta - inv(optimization$Hess) %*% optimization$grad
      optimization = func(x, y, beta_new)
    }
    previous_loglik = -optimization$loglik
    beta = beta_new
    step = step + 1
  }
}


```


# Loading the data
```{r}
cancer_data = read_csv("./breast-cancer.csv")

# Assign x values
x = cancer_data %>% 
  select(-id, -diagnosis) 

# Standardize x values
# Function to standardize
standardize = function(col) {
  mean = mean(col)
  stdev = sd(col)
  return((col - mean)/stdev)
}

x = x %>% 
  map_df(., standardize) %>% 
  mutate(intercept = 1) %>% 
  as.matrix()

# Assign cancer diagnosis as y values
y = cancer_data %>% 
  select(diagnosis) %>% 
  mutate(diagnosis = ifelse(diagnosis == "M", 1, 0)) %>% 
  as.matrix()

beta = matrix(rep(0, ncol(x)))

test = newton_optimize(x, y, beta = beta)
func(x, y, beta)
```